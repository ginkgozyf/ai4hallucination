#!/usr/bin/env python3
"""
ç”Ÿæˆä¸‰ä¸ªå®éªŒæ•°æ®é›†çš„è¯¦ç»†presentationæ–‡æ¡£
æ¯ä¸ªæ•°æ®é›†15ä¸ªæ ·ä¾‹,åŒ…å«é—®é¢˜ã€ç­”æ¡ˆã€æ£€ç´¢å†…å®¹ã€æ¨¡å‹è¾“å‡ºå’Œè¯„åˆ†
"""

import json
import os
from typing import List, Dict, Any, Tuple

# æ•°æ®æ–‡ä»¶è·¯å¾„
DATA_PATHS = {
    'exp1_popqa': {
        'jsonl': 'self-rag/eval_data/popqa_longtail_w_gs.jsonl',
        'preds': 'self-rag/retrieval_lm/exp1',
        'eval': 'self-rag/ragas_results/exp1_popqa_simple_eval.json',
        'name': 'PopQA (çŸ¥è¯†é—®ç­”)',
        'desc': 'åŸºäºWikipediaçš„é•¿å°¾çŸ¥è¯†é—®ç­”ä»»åŠ¡'
    },
    'exp2_arc': {
        'jsonl': 'self-rag/eval_data/arc_challenge_processed.jsonl',
        'preds': 'self-rag/retrieval_lm/exp2',
        'eval': 'self-rag/ragas_results/exp2_arc_simple_eval.json',
        'name': 'ARC (ç§‘å­¦æ¨ç†)',
        'desc': 'AI2æ¨ç†æŒ‘æˆ˜ - ç§‘å­¦å¤šé¡¹é€‰æ‹©é¢˜'
    },
    'exp3_health': {
        'jsonl': 'self-rag/eval_data/health_claims_processed.jsonl',
        'preds': 'self-rag/retrieval_lm/exp3_debug',
        'eval': 'self-rag/ragas_results/exp3_health_simple_eval.json',
        'name': 'Health Claims (å¥åº·å£°æ˜éªŒè¯)',
        'desc': 'å¥åº·ç›¸å…³å£°æ˜çš„çœŸå‡åˆ¤æ–­ä»»åŠ¡'
    }
}

BASE_DIR = '/data/ai4hallucination'


def load_jsonl(file_path: str, max_lines: int = 50) -> List[Dict]:
    """åŠ è½½JSONLæ–‡ä»¶"""
    data = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            if i >= max_lines:
                break
            data.append(json.loads(line.strip()))
    return data


def load_json(file_path: str) -> Dict:
    """åŠ è½½JSONæ–‡ä»¶"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def select_diverse_samples(scores: List[Dict], n_samples: int = 15) -> List[int]:
    """
    é€‰æ‹©å¤šæ ·åŒ–çš„æ ·æœ¬ç´¢å¼•
    ç­–ç•¥: 5ä¸ªé«˜åˆ† + 5ä¸ªä¸­ç­‰ + 5ä¸ªä½åˆ†
    """
    # ä¸ºæ¯ä¸ªæ ·æœ¬è®¡ç®—ç»¼åˆå¾—åˆ†
    sample_scores = []
    for idx, (rel, corr) in enumerate(zip(scores['relevancy'], scores['correctness'])):
        sample_scores.append({
            'idx': idx,
            'relevancy': rel,
            'correctness': corr,
            'avg': (rel + corr) / 2
        })

    # æŒ‰æ­£ç¡®æ€§åˆ†ç»„
    high_score = [s for s in sample_scores if s['correctness'] == 1.0]
    low_score = [s for s in sample_scores if s['correctness'] == 0.0]
    mid_score = [s for s in sample_scores if 0.0 < s['correctness'] < 1.0]

    # å¦‚æœä¸­ç­‰åˆ†æ•°æ ·æœ¬ä¸è¶³,ä»é«˜åˆ†å’Œä½åˆ†ä¸­è¡¥å……
    if len(mid_score) < 5:
        mid_score = [s for s in sample_scores if 0.3 <= s['correctness'] <= 0.7]

    # é€‰æ‹©æ ·æœ¬
    selected = []

    # é«˜åˆ†æ ·æœ¬ - æŒ‰ç›¸å…³æ€§æ’åºé€‰top5
    high_score.sort(key=lambda x: x['relevancy'], reverse=True)
    selected.extend([s['idx'] for s in high_score[:5]])

    # ä¸­ç­‰æ ·æœ¬ - é€‰æ‹©å¤šæ ·æ€§
    mid_score.sort(key=lambda x: x['avg'])
    step = max(1, len(mid_score) // 5) if mid_score else 1
    selected.extend([mid_score[i]['idx'] for i in range(0, min(len(mid_score), 5 * step), step)][:5])

    # ä½åˆ†æ ·æœ¬ - æŒ‰ç›¸å…³æ€§æ’åºé€‰top5
    low_score.sort(key=lambda x: x['relevancy'], reverse=True)
    selected.extend([s['idx'] for s in low_score[:5]])

    # å¦‚æœæ ·æœ¬ä¸è¶³15ä¸ª,ä»å‰©ä½™æ ·æœ¬ä¸­è¡¥å……
    if len(selected) < n_samples:
        remaining = [s['idx'] for s in sample_scores if s['idx'] not in selected]
        selected.extend(remaining[:n_samples - len(selected)])

    return sorted(selected[:n_samples])


def format_sample_popqa(idx: int, raw_data: Dict, pred: str, scores: Dict) -> str:
    """æ ¼å¼åŒ–PopQAæ ·ä¾‹"""
    question = raw_data['question']
    answers = raw_data['answers']
    ctxs = raw_data.get('ctxs', [])[:3]  # åªå–å‰3ä¸ªæ£€ç´¢ç»“æœ

    relevancy = scores['relevancy'][idx]
    correctness = scores['correctness'][idx]

    # åˆ†æç»“æœ
    if correctness >= 0.8:
        quality = "âœ… é«˜è´¨é‡"
        analysis = "æ¨¡å‹å›ç­”æ­£ç¡®ä¸”ç›¸å…³"
    elif correctness >= 0.3:
        quality = "âš ï¸ éƒ¨åˆ†æ­£ç¡®"
        analysis = "æ¨¡å‹å›ç­”éƒ¨åˆ†æ­£ç¡®æˆ–ä¸å¤Ÿç²¾ç¡®"
    else:
        quality = "âŒ é”™è¯¯"
        analysis = "æ¨¡å‹å›ç­”é”™è¯¯æˆ–ä¸ç›¸å…³"

    markdown = f"""
---

### æ ·ä¾‹ #{idx + 1} - {quality}

**é—®é¢˜:**
> {question}

**çœŸå®ç­”æ¡ˆ:**
- {', '.join([f'"{ans}"' for ans in answers])}

**æ£€ç´¢å†…å®¹ (Top 3):**
"""

    for i, ctx in enumerate(ctxs, 1):
        score = ctx.get('score', 'N/A')
        title = ctx.get('title', 'Unknown')
        text = ctx.get('text', '')[:200] + '...' if len(ctx.get('text', '')) > 200 else ctx.get('text', '')
        markdown += f"""
{i}. **{title}** (ç›¸å…³æ€§å¾—åˆ†: {score})
   ```
   {text}
   ```
"""

    markdown += f"""
**æ¨¡å‹ç­”æ¡ˆ:**
```
{pred}
```

**è¯„ä¼°å¾—åˆ†:**
- **Relevancy (ç›¸å…³æ€§)**: {relevancy:.2f}
- **Correctness (æ­£ç¡®æ€§)**: {correctness:.2f}

**åˆ†æ:** {analysis}

"""

    if relevancy > 0.5 and correctness == 0:
        markdown += "**æ³¨æ„**: æ£€ç´¢åˆ°äº†ç›¸å…³å†…å®¹ä½†ç­”æ¡ˆé”™è¯¯,å¯èƒ½æ˜¯ç­”æ¡ˆæå–æˆ–æ¨ç†ç¯èŠ‚å‡ºç°é—®é¢˜ã€‚\n"
    elif relevancy < 0.5 and correctness > 0.5:
        markdown += "**æ³¨æ„**: æ£€ç´¢ç›¸å…³æ€§ä½ä½†ç­”æ¡ˆæ­£ç¡®,è¯´æ˜æ¨¡å‹å¯èƒ½ä¾èµ–å†…éƒ¨çŸ¥è¯†è€Œéæ£€ç´¢å†…å®¹ã€‚\n"

    # å¯è§†åŒ–å›¾è¡¨
    markdown += f"""
```mermaid
xychart-beta
    title "æ ·ä¾‹#{idx + 1} è¯„åˆ†"
    x-axis ["Relevancy", "Correctness"]
    y-axis "Score" 0 --> 1.0
    bar [{relevancy:.2f}, {correctness:.2f}]
```
"""

    return markdown


def format_sample_arc(idx: int, raw_data: Dict, pred: str, scores: Dict) -> str:
    """æ ¼å¼åŒ–ARCæ ·ä¾‹"""
    question = raw_data['question']
    choices = raw_data['choices']
    answer_key = raw_data['answerKey']
    ctxs = raw_data.get('ctxs', [])[:3]

    relevancy = scores['relevancy'][idx]
    correctness = scores['correctness'][idx]

    # æ ¼å¼åŒ–é€‰é¡¹
    options_text = []
    for label, text in zip(choices['label'], choices['text']):
        marker = "âœ“" if label == answer_key else " "
        options_text.append(f"  [{marker}] {label}. {text}")

    # åˆ†æ
    if correctness >= 0.8:
        quality = "âœ… æ­£ç¡®"
        analysis = "æ¨¡å‹é€‰æ‹©äº†æ­£ç¡®ç­”æ¡ˆ"
    else:
        quality = "âŒ é”™è¯¯"
        analysis = f"æ¨¡å‹é€‰æ‹©é”™è¯¯,æ­£ç¡®ç­”æ¡ˆåº”ä¸º {answer_key}"

    markdown = f"""
---

### æ ·ä¾‹ #{idx + 1} - {quality}

**é—®é¢˜:**
> {question}

**é€‰é¡¹:**
{chr(10).join(options_text)}

**æ­£ç¡®ç­”æ¡ˆ:** {answer_key}

**æ£€ç´¢å†…å®¹ (Top 3):**
"""

    for i, ctx in enumerate(ctxs, 1):
        score = ctx.get('score', 'N/A')
        title = ctx.get('title', 'Unknown')
        text = ctx.get('text', '')[:200] + '...' if len(ctx.get('text', '')) > 200 else ctx.get('text', '')
        markdown += f"""
{i}. **{title}** (ç›¸å…³æ€§å¾—åˆ†: {score})
   ```
   {text}
   ```
"""

    markdown += f"""
**æ¨¡å‹é€‰æ‹©:**
```
{pred}
```

**è¯„ä¼°å¾—åˆ†:**
- **Relevancy (ç›¸å…³æ€§)**: {relevancy:.2f}
- **Correctness (æ­£ç¡®æ€§)**: {correctness:.2f}

**åˆ†æ:** {analysis}

"""

    if relevancy < 0.1:
        markdown += "**âš ï¸ æ£€ç´¢å¤±æ•ˆ**: æ£€ç´¢ç›¸å…³æ€§æä½,æ¨¡å‹ä¸»è¦ä¾èµ–é¢„è®­ç»ƒçŸ¥è¯†å›ç­”ã€‚\n"

    markdown += f"""
```mermaid
xychart-beta
    title "æ ·ä¾‹#{idx + 1} è¯„åˆ†"
    x-axis ["Relevancy", "Correctness"]
    y-axis "Score" 0 --> 1.0
    bar [{relevancy:.2f}, {correctness:.2f}]
```
"""

    return markdown


def format_sample_health(idx: int, raw_data: Dict, pred: str, scores: Dict) -> str:
    """æ ¼å¼åŒ–Health Claimsæ ·ä¾‹"""
    claim = raw_data.get('claim', raw_data.get('question', ''))
    label = raw_data['label']
    answers = raw_data.get('answers', [])
    ctxs = raw_data.get('ctxs', [])[:3]

    relevancy = scores['relevancy'][idx]
    correctness = scores['correctness'][idx]

    # æ ‡ç­¾è½¬æ¢
    label_zh = "âœ… çœŸå®" if label == "SUPPORTS" else "âŒ è™šå‡"

    # åˆ†æ
    if correctness >= 0.8:
        quality = "âœ… åˆ¤æ–­æ­£ç¡®"
        analysis = f"æ¨¡å‹æ­£ç¡®åˆ¤æ–­è¯¥å£°æ˜ä¸º{label_zh}"
    else:
        quality = "âŒ åˆ¤æ–­é”™è¯¯"
        analysis = f"æ¨¡å‹åˆ¤æ–­é”™è¯¯,è¯¥å£°æ˜å®é™…ä¸º{label_zh}"

    markdown = f"""
---

### æ ·ä¾‹ #{idx + 1} - {quality}

**å¥åº·å£°æ˜:**
> {claim}

**çœŸå®æ ‡ç­¾:** {label} ({label_zh})

**æ ‡å‡†ç­”æ¡ˆ:** {', '.join([f'"{ans}"' for ans in answers])}

**æ£€ç´¢å†…å®¹ (Top 3):**
"""

    for i, ctx in enumerate(ctxs, 1):
        score = ctx.get('score', 'N/A')
        title = ctx.get('title', 'Unknown')
        text = ctx.get('text', '')[:200] + '...' if len(ctx.get('text', '')) > 200 else ctx.get('text', '')
        markdown += f"""
{i}. **{title}** (ç›¸å…³æ€§å¾—åˆ†: {score})
   ```
   {text}
   ```
"""

    markdown += f"""
**æ¨¡å‹åˆ¤æ–­:**
```
{pred}
```

**è¯„ä¼°å¾—åˆ†:**
- **Relevancy (ç›¸å…³æ€§)**: {relevancy:.2f}
- **Correctness (æ­£ç¡®æ€§)**: {correctness:.2f}

**åˆ†æ:** {analysis}

"""

    if relevancy > 0.5 and correctness == 0:
        markdown += "**âš ï¸ æ¨ç†é”™è¯¯**: æ£€ç´¢åˆ°ç›¸å…³è¯æ®ä½†åˆ¤æ–­é”™è¯¯,å¯èƒ½æ˜¯æ¨ç†é€»è¾‘é—®é¢˜ã€‚\n"
    elif relevancy < 0.3:
        markdown += "**âš ï¸ æ£€ç´¢ä¸è¶³**: æ£€ç´¢ç›¸å…³æ€§ä½,å¯èƒ½ç¼ºå°‘å…³é”®è¯æ®ã€‚\n"

    markdown += f"""
```mermaid
xychart-beta
    title "æ ·ä¾‹#{idx + 1} è¯„åˆ†"
    x-axis ["Relevancy", "Correctness"]
    y-axis "Score" 0 --> 1.0
    bar [{relevancy:.2f}, {correctness:.2f}]
```
"""

    return markdown


def generate_dataset_report(exp_key: str) -> str:
    """ç”Ÿæˆå•ä¸ªæ•°æ®é›†çš„è¯¦ç»†æŠ¥å‘Š"""
    config = DATA_PATHS[exp_key]

    # åŠ è½½æ•°æ®
    print(f"å¤„ç† {exp_key}...")
    raw_data = load_jsonl(os.path.join(BASE_DIR, config['jsonl']))
    pred_data = load_json(os.path.join(BASE_DIR, config['preds']))
    eval_data = load_json(os.path.join(BASE_DIR, config['eval']))

    preds = pred_data['preds']
    scores = eval_data['individual_scores']
    metrics = eval_data['metrics']

    # é€‰æ‹©15ä¸ªæ ·æœ¬
    selected_indices = select_diverse_samples(scores, n_samples=15)
    print(f"  é€‰æ‹©çš„æ ·æœ¬ç´¢å¼•: {selected_indices}")

    # ç”ŸæˆæŠ¥å‘Šå¤´éƒ¨
    markdown = f"""# {config['name']} - è¯¦ç»†æ ·ä¾‹åˆ†æ

## ğŸ“Š æ•°æ®é›†æ¦‚è§ˆ

**æ•°æ®é›†åç§°:** {config['name']}

**ä»»åŠ¡æè¿°:** {config['desc']}

**è¯„ä¼°æ ·æœ¬æ•°:** {eval_data['num_samples']} (ç´¢å¼• {eval_data['start_idx']}-{eval_data['end_idx'] - 1})

**æœ¬æŠ¥å‘Šæ ·ä¾‹æ•°:** 15ä¸ªä»£è¡¨æ€§æ ·ä¾‹

## ğŸ“ˆ æ•´ä½“æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | åˆ†æ•° | è¯´æ˜ |
|------|------|------|
| **Relevancy (ç›¸å…³æ€§)** | {metrics['relevancy']:.3f} ({metrics['relevancy']*100:.1f}%) | æ£€ç´¢å†…å®¹ä¸é—®é¢˜çš„ç›¸å…³ç¨‹åº¦ |
| **Correctness (æ­£ç¡®æ€§)** | {metrics['correctness']:.3f} ({metrics['correctness']*100:.1f}%) | ç­”æ¡ˆçš„å‡†ç¡®æ€§ |

### æ•´ä½“å¾—åˆ†åˆ†å¸ƒ

```mermaid
xychart-beta
    title "æ•´ä½“æ€§èƒ½å¯¹æ¯”"
    x-axis ["Relevancy", "Correctness"]
    y-axis "Score" 0 --> 1.0
    bar [{metrics['relevancy']:.3f}, {metrics['correctness']:.3f}]
```

### æ ·æœ¬è´¨é‡åˆ†å¸ƒ

```mermaid
pie
    title "æ­£ç¡®æ€§åˆ†å¸ƒ (50ä¸ªè¯„ä¼°æ ·æœ¬)"
    "å®Œå…¨æ­£ç¡® (1.0)": {sum(1 for s in scores['correctness'] if s == 1.0)}
    "éƒ¨åˆ†æ­£ç¡® (0.5)": {sum(1 for s in scores['correctness'] if s == 0.5)}
    "å®Œå…¨é”™è¯¯ (0.0)": {sum(1 for s in scores['correctness'] if s == 0.0)}
```

---

## ğŸ“ è¯¦ç»†æ ·ä¾‹åˆ†æ

ä»¥ä¸‹15ä¸ªæ ·ä¾‹æŒ‰è´¨é‡åˆ†ä¸ºä¸‰ç»„:
- **é«˜è´¨é‡æ ·ä¾‹** (æ­£ç¡®æ€§ = 1.0): 5ä¸ª
- **ä¸­ç­‰è´¨é‡æ ·ä¾‹** (0 < æ­£ç¡®æ€§ < 1.0): 5ä¸ª
- **ä½è´¨é‡æ ·ä¾‹** (æ­£ç¡®æ€§ = 0.0): 5ä¸ª

"""

    # ç”Ÿæˆæ¯ä¸ªæ ·ä¾‹
    format_func = {
        'exp1_popqa': format_sample_popqa,
        'exp2_arc': format_sample_arc,
        'exp3_health': format_sample_health
    }[exp_key]

    for idx in selected_indices:
        markdown += format_func(idx, raw_data[idx], preds[idx], scores)

    # æ·»åŠ æ€»ç»“
    correct_count = sum(1 for i in selected_indices if scores['correctness'][i] == 1.0)
    incorrect_count = sum(1 for i in selected_indices if scores['correctness'][i] == 0.0)
    partial_count = 15 - correct_count - incorrect_count

    markdown += f"""
---

## ğŸ¯ æ ·ä¾‹æ€»ç»“

### æœ¬æ‰¹æ¬¡15ä¸ªæ ·ä¾‹çš„è¡¨ç°

| è´¨é‡ç­‰çº§ | æ•°é‡ | å æ¯” |
|---------|------|------|
| âœ… å®Œå…¨æ­£ç¡® | {correct_count} | {correct_count/15*100:.1f}% |
| âš ï¸ éƒ¨åˆ†æ­£ç¡® | {partial_count} | {partial_count/15*100:.1f}% |
| âŒ å®Œå…¨é”™è¯¯ | {incorrect_count} | {incorrect_count/15*100:.1f}% |

### å…³é”®å‘ç°

"""

    # æ·»åŠ é’ˆå¯¹æ€§åˆ†æ
    if exp_key == 'exp1_popqa':
        markdown += """
1. **æ£€ç´¢è¡¨ç°ä¼˜ç§€**: ç›¸å…³æ€§é«˜è¾¾92%,è¯´æ˜æ£€ç´¢ç³»ç»Ÿèƒ½æœ‰æ•ˆæ‰¾åˆ°ç›¸å…³çŸ¥è¯†
2. **ç­”æ¡ˆæå–éœ€æ”¹è¿›**: æ­£ç¡®æ€§ä»…63%,è¯´æ˜ä»æ£€ç´¢å†…å®¹ä¸­æå–ç²¾ç¡®ç­”æ¡ˆå­˜åœ¨å›°éš¾
3. **å¸¸è§é”™è¯¯**: ç­”æ¡ˆä¸å¤Ÿç²¾ç¡®ã€åŒ…å«å¤šä½™ä¿¡æ¯ã€æˆ–æå–äº†é”™è¯¯çš„å®ä½“

**æ”¹è¿›å»ºè®®:**
- ä¼˜åŒ–ç­”æ¡ˆæå–ç®—æ³•,æé«˜ç²¾ç¡®åº¦
- åŠ å¼ºç­”æ¡ˆéªŒè¯æœºåˆ¶
- æ”¹è¿›æç¤ºè¯è®¾è®¡,æ˜ç¡®è¦æ±‚ç®€æ´ç­”æ¡ˆ
"""
    elif exp_key == 'exp2_arc':
        markdown += """
1. **æ£€ç´¢ç³»ç»Ÿå¤±æ•ˆ**: ç›¸å…³æ€§ä»…0.4%,å‡ ä¹æ²¡æœ‰æ£€ç´¢åˆ°æœ‰æ•ˆä¿¡æ¯
2. **ä¾èµ–å†…éƒ¨çŸ¥è¯†**: æ­£ç¡®ç‡ä»è¾¾76%,è¯´æ˜æ¨¡å‹ä¸»è¦ä¾èµ–é¢„è®­ç»ƒçŸ¥è¯†
3. **æ£€ç´¢æœªå‘æŒ¥ä½œç”¨**: ç§‘å­¦æ¨ç†ä»»åŠ¡ä¸­RAGç­–ç•¥æœªç”Ÿæ•ˆ

**æ”¹è¿›å»ºè®®:**
- æ£€æŸ¥ç§‘å­¦çŸ¥è¯†åº“çš„è¦†ç›–åº¦
- ä¼˜åŒ–ç§‘å­¦é—®é¢˜çš„æŸ¥è¯¢é‡å†™ç­–ç•¥
- è€ƒè™‘å¢å¼ºç§‘å­¦é¢†åŸŸçš„é¢„è®­ç»ƒæˆ–å¾®è°ƒ
- å®æ–½æ··åˆç­–ç•¥:æ£€ç´¢+ç”Ÿæˆ
"""
    elif exp_key == 'exp3_health':
        markdown += """
1. **æ£€ç´¢è´¨é‡ä¸ç¨³å®š**: ç›¸å…³æ€§44.6%,åœ¨ä¸åŒæ ·æœ¬é—´å·®å¼‚è¾ƒå¤§
2. **åˆ¤æ–­å‡†ç¡®ç‡è‰¯å¥½**: æ­£ç¡®ç‡70%,è¯´æ˜æ¨¡å‹æœ‰ä¸€å®šäº‹å®æ ¸æŸ¥èƒ½åŠ›
3. **æ£€ç´¢èµ·è¾…åŠ©ä½œç”¨**: æ£€ç´¢å†…å®¹å¯¹åˆ¤æ–­æœ‰å¸®åŠ©ä½†éå†³å®šæ€§

**æ”¹è¿›å»ºè®®:**
- å¢å¼ºåŒ»å­¦å¥åº·é¢†åŸŸçš„æ£€ç´¢è¯­æ–™
- å®æ–½å¤šæ–‡æ¡£äº¤å‰éªŒè¯æœºåˆ¶
- ä¼˜åŒ–æŸ¥è¯¢æ„å»º,æé«˜æ£€ç´¢å¬å›ç‡
- åŠ å…¥äº‹å®æ ¸æŸ¥ä¸“ç”¨æ¨¡å—
"""

    markdown += """
---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: 2025-11-05*
"""

    return markdown


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ç”Ÿæˆè¯¦ç»†Presentationæ–‡æ¡£ (æ¯ä¸ªæ•°æ®é›†15ä¸ªæ ·ä¾‹)")
    print("=" * 60)

    # ç”Ÿæˆä¸‰ä¸ªæ•°æ®é›†çš„è¯¦ç»†æŠ¥å‘Š
    for exp_key in ['exp1_popqa', 'exp2_arc', 'exp3_health']:
        report = generate_dataset_report(exp_key)

        # ä¿å­˜æ–‡ä»¶
        output_file = os.path.join(BASE_DIR, f'presentation_{exp_key}_15samples.md')
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"âœ… å·²ç”Ÿæˆ: {output_file}")
        print()

    print("=" * 60)
    print("æ‰€æœ‰æŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
    print("=" * 60)


if __name__ == '__main__':
    main()
