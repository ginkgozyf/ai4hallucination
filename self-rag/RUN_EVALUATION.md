# è¿è¡Œ RAGAS è¯„ä¼° / Run RAGAS Evaluation

## å¿«é€Ÿå¼€å§‹ / Quick Start

### 1. è®¾ç½® API å¯†é’¥ / Set API Key

```bash
export DEEPSEEK_API_KEY='your-deepseek-api-key-here'
```

è·å–å¯†é’¥ / Get key: https://platform.deepseek.com/

### 2. æ£€æŸ¥è®¾ç½® / Check Setup

```bash
cd /data/self-rag
./setup_ragas_eval.sh
```

### 3. è¿è¡Œè¯„ä¼° / Run Evaluation

```bash
# 20 samples per experiment (recommended - æ¨è)
python3 evaluate_with_ragas.py

# Or 10 samples per experiment (faster - æ›´å¿«)
python3 evaluate_with_ragas_simple.py
```

## å½“å‰é…ç½® / Current Configuration

### evaluate_with_ragas.py

- **æ¯ä¸ªå®éªŒæ ·æœ¬æ•° Samples per experiment**: 20
- **æ€»æ ·æœ¬æ•° Total samples**: 60 (20 Ã— 3)
- **é¢„è®¡æ—¶é—´ Estimated time**: 5-10 åˆ†é’Ÿ minutes
- **API æˆæœ¬ API cost**: ä½ Low (~98% reduction vs full)

### evaluate_with_ragas_simple.py

- **æ¯ä¸ªå®éªŒæ ·æœ¬æ•° Samples per experiment**: 10
- **æ€»æ ·æœ¬æ•° Total samples**: 30 (10 Ã— 3)
- **é¢„è®¡æ—¶é—´ Estimated time**: 2-5 åˆ†é’Ÿ minutes
- **API æˆæœ¬ API cost**: æä½ Very Low

## è¯„ä¼°çš„å®éªŒ / Experiments Evaluated

| # | å®éªŒåç§°<br>Experiment | ä»»åŠ¡ç±»å‹<br>Task | æ ·æœ¬æ•°<br>Samples |
|---|---|---|---|
| 1 | exp1_popqa | PopQA é—®ç­”<br>Question Answering | 20 |
| 2 | exp2_arc | ARC Challenge é€‰æ‹©é¢˜<br>Multiple Choice | 20 |
| 3 | exp3_health | å¥åº·å£°æ˜éªŒè¯<br>Health Claims | 20 |

## ç»“æœä½ç½® / Results Location

è¯„ä¼°å®Œæˆåï¼Œç»“æœå°†ä¿å­˜åœ¨ï¼š

**Results will be saved to:**

```
ragas_results/
â”œâ”€â”€ exp1_popqa_ragas_eval.json     â† PopQA è¯„ä¼°ç»“æœ
â”œâ”€â”€ exp2_arc_ragas_eval.json       â† ARC Challenge è¯„ä¼°ç»“æœ
â”œâ”€â”€ exp3_health_ragas_eval.json    â† Health Claims è¯„ä¼°ç»“æœ
â””â”€â”€ summary.json                   â† æ€»ç»“ Summary
```

## æŸ¥çœ‹ç»“æœ / View Results

### æ–¹æ³•1: ç›´æ¥æŸ¥çœ‹ JSON / View JSON Directly

```bash
# æŸ¥çœ‹å•ä¸ªå®éªŒç»“æœ
cat ragas_results/exp1_popqa_ragas_eval.json

# æŸ¥çœ‹æ€»ç»“
cat ragas_results/summary.json
```

### æ–¹æ³•2: ä½¿ç”¨ Python / Using Python

```python
import json

# è¯»å–ç»“æœ
with open('ragas_results/summary.json', 'r') as f:
    results = json.load(f)

# æ˜¾ç¤ºæ‰€æœ‰å®éªŒçš„æŒ‡æ ‡
for exp in results['experiments']:
    print(f"\n{exp['experiment']}:")
    for metric, score in exp['metrics'].items():
        print(f"  {metric}: {score:.4f}")
```

### æ–¹æ³•3: ä½¿ç”¨ jq å·¥å…· / Using jq

```bash
# å®‰è£… jq (å¦‚æœæœªå®‰è£…)
# sudo apt-get install jq  # Ubuntu/Debian
# brew install jq          # macOS

# æŸ¥çœ‹æ‰€æœ‰å®éªŒçš„ answer_relevancy åˆ†æ•°
jq '.experiments[] | {experiment: .experiment, relevancy: .metrics.answer_relevancy}' ragas_results/summary.json

# æŸ¥çœ‹æŸä¸ªå®éªŒçš„æ‰€æœ‰æŒ‡æ ‡
jq '.experiments[] | select(.experiment == "exp1_popqa") | .metrics' ragas_results/summary.json
```

## é¢„æœŸè¾“å‡ºç¤ºä¾‹ / Expected Output Example

```
================================================================================
RAGAS Evaluation - Limited Mode
Evaluating 20 samples per experiment
================================================================================

================================================================================
Evaluating exp1_popqa
(Limited to 20 samples)
================================================================================

Loading results from: retrieval_lm/exp1
Loaded 20 samples
Sample preview:
  Question: What is Henry Feilden's occupation?...
  Answer: Henry Feilden is a British Army officer....
  Ground Truth: politician...

Initializing DeepSeek-R1 LLM...
Creating RAGAS dataset...
Metrics to evaluate: ['AnswerRelevancy', 'AnswerCorrectness']

Running RAGAS evaluation on 20 samples (this may take a while)...
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:15<00:00,  6.78s/it]

================================================================================
Results for exp1_popqa:
================================================================================
  answer_relevancy: 0.8234
  answer_correctness: 0.7156

Results saved to: ragas_results/exp1_popqa_ragas_eval.json
```

## ç»“æœè§£è¯» / Understanding Results

### æŒ‡æ ‡å«ä¹‰ / Metrics Explained

| æŒ‡æ ‡<br>Metric | å«ä¹‰<br>Meaning | èŒƒå›´<br>Range | è¶Šé«˜è¶Šå¥½<br>Higher is Better |
|---|---|---|---|
| **answer_relevancy** | ç­”æ¡ˆä¸é—®é¢˜çš„ç›¸å…³æ€§<br>Answer relevance to question | 0-1 | âœ“ |
| **answer_correctness** | ç­”æ¡ˆçš„æ­£ç¡®æ€§<br>Answer correctness | 0-1 | âœ“ |
| **faithfulness** | ç­”æ¡ˆå¯¹ä¸Šä¸‹æ–‡çš„å¿ å®åº¦<br>Faithfulness to context | 0-1 | âœ“ |
| **context_precision** | ä¸Šä¸‹æ–‡æ’åºè´¨é‡<br>Context ranking quality | 0-1 | âœ“ |
| **context_recall** | ä¸Šä¸‹æ–‡ä¿¡æ¯è¦†ç›–<br>Context information coverage | 0-1 | âœ“ |

### åˆ†æ•°å‚è€ƒ / Score Reference

- **0.9-1.0**: ä¼˜ç§€ Excellent
- **0.8-0.9**: è‰¯å¥½ Good
- **0.7-0.8**: ä¸­ç­‰ Fair
- **0.6-0.7**: éœ€æ”¹è¿› Needs Improvement
- **< 0.6**: è¾ƒå·® Poor

## å¸¸è§é—®é¢˜ / FAQ

### Q1: å¦‚ä½•ä¿®æ”¹æ ·æœ¬æ•°é‡ï¼Ÿ

**A1:** ç¼–è¾‘ `evaluate_with_ragas.py` ç¬¬263è¡Œï¼š

```python
MAX_SAMPLES = 20  # æ”¹ä¸ºä½ æƒ³è¦çš„æ•°é‡ Change to desired number
```

æˆ–è®¾ç½®ä¸º `None` è¯„ä¼°æ‰€æœ‰æ ·æœ¬ï¼š

```python
MAX_SAMPLES = None  # Evaluate all samples
```

### Q2: è¯„ä¼°æ—¶é—´å¤ªé•¿æ€ä¹ˆåŠï¼Ÿ

**A2:**
- ä½¿ç”¨æ›´å°‘çš„æ ·æœ¬ (å¦‚10ä¸ª)
- ä½¿ç”¨ `evaluate_with_ragas_simple.py`
- æ£€æŸ¥ç½‘ç»œè¿æ¥

### Q3: API è°ƒç”¨å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**A3:**
- æ£€æŸ¥ API å¯†é’¥æ˜¯å¦æ­£ç¡®
- ç¡®è®¤ API é…é¢å……è¶³
- æ£€æŸ¥ç½‘ç»œè¿æ¥
- æŸ¥çœ‹é”™è¯¯æ—¥å¿—

### Q4: å¦‚ä½•æ¯”è¾ƒä¸åŒå®éªŒï¼Ÿ

**A4:** åˆ›å»ºä¸€ä¸ªç®€å•çš„æ¯”è¾ƒè„šæœ¬ï¼š

```python
import json

with open('ragas_results/summary.json', 'r') as f:
    data = json.load(f)

print("Experiment Comparison:")
print("-" * 60)
for exp in data['experiments']:
    name = exp['experiment']
    rel = exp['metrics'].get('answer_relevancy', 0)
    cor = exp['metrics'].get('answer_correctness', 0)
    print(f"{name:20} | Relevancy: {rel:.4f} | Correctness: {cor:.4f}")
```

## ä¸‹ä¸€æ­¥ / Next Steps

1. âœ… è¿è¡Œè¯„ä¼°
2. âœ… æŸ¥çœ‹ç»“æœ
3. âœ… åˆ†æå„å®éªŒçš„æ€§èƒ½
4. âœ… æ ¹æ®éœ€è¦è°ƒæ•´æ ·æœ¬æ•°é‡
5. âœ… æ¯”è¾ƒä¸åŒå®éªŒçš„è¡¨ç°

## æ•…éšœæ’é™¤ / Troubleshooting

### é—®é¢˜: å¯¼å…¥é”™è¯¯

```
ImportError: No module named 'ragas'
```

**è§£å†³:**
```bash
pip install ragas openai datasets
```

### é—®é¢˜: API å¯†é’¥æœªè®¾ç½®

```
Error: DEEPSEEK_API_KEY environment variable not set
```

**è§£å†³:**
```bash
export DEEPSEEK_API_KEY='your-key'
```

### é—®é¢˜: æ–‡ä»¶æœªæ‰¾åˆ°

```
FileNotFoundError: retrieval_lm/exp1
```

**è§£å†³:** ç¡®è®¤ä½ åœ¨æ­£ç¡®çš„ç›®å½•ï¼š
```bash
cd /data/self-rag
pwd  # åº”æ˜¾ç¤º /data/self-rag
```

## è·å–å¸®åŠ© / Get Help

- ğŸ“– è¯¦ç»†æ–‡æ¡£: `RAGAS_EVALUATION_README.md`
- ğŸš€ å¿«é€Ÿå…¥é—¨: `QUICKSTART_RAGAS.md`
- ğŸ“ é¡¹ç›®æ€»ç»“: `RAGAS_INTEGRATION_SUMMARY.md`
- ğŸ“‹ ä¿®æ”¹è¯´æ˜: `CHANGES.md`

---

**æœ€åæ›´æ–° Last Updated**: 2025-10-29

**çŠ¶æ€ Status**: âœ… å°±ç»ª Ready to Run
